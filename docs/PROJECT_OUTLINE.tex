\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{hyperref}
\usepackage{enumitem}

\title{Project Outline:\\Lucy Manifesto Revitalization (GA144)}
\author{Prepared from source.pdf analysis}
\date{\today}

\begin{document}
\maketitle

\section{Mission}
Revitalize the original Lucy android program by preserving the author's core thesis:
\begin{itemize}
  \item intelligence must be embodied
  \item sensors and actuators must be biologically meaningful
  \item intelligence should emerge from distributed interacting modules, not a single scripted controller
\end{itemize}
Implement this with a modern architecture centered on \texttt{GA144} manycore chips for low-power, massively parallel, real-time sensorimotor processing.

\section{What We Preserve From The Author}
From \texttt{source.pdf}, we keep these design commitments:
\begin{itemize}
  \item Body-first AI: build in hardware, not only simulation.
  \item Realistic sensorimotor loops: vision, hearing, proprioception, and muscle-like control.
  \item Bottom-up composition: many small processing units configured as functional building blocks.
  \item Developmental learning: avoid hard-coded symbolic behavior and let capability emerge through interaction.
\end{itemize}

\section{Why GA144 For The Revitalization}
\begin{itemize}
  \item High parallelism supports many simultaneous low-latency loops.
  \item Excellent power profile for always-on embedded cognition.
  \item Natural fit for distributed ``microcircuit'' style architecture aligned with Lucy's original philosophy.
\end{itemize}
\noindent\textbf{Note:} the source text emphasizes distributed microcontrollers (PIC-era design) rather than GA144 specifically; this project upgrades that architecture to GA144-class manycore implementation.

\section{System Vision (Lucy v2)}
Lucy v2 is a torso/head/arms developmental android platform with:
\begin{itemize}
  \item compliant, muscle-like actuation abstractions over practical motors
  \item biologically-inspired sensing pipelines (retina-like vision transforms, cochlea-like audio maps)
  \item layered learning loops from reflex to adaptive behavior
  \item distributed compute fabric on GA144 chips with explicit inter-core messaging
\end{itemize}

\section{Technical Architecture}
\subsection{1. Compute Fabric}
\begin{itemize}
  \item GA144 node clusters partitioned by function: sensor front-end, motor control, integration/reflex, learning/plasticity, and safety/supervisory.
  \item Deterministic message-passing protocol between clusters.
  \item Real-time telemetry and debug bridge to host workstation.
\end{itemize}

\subsection{2. Embodiment Layer}
\begin{itemize}
  \item Upper-body kinematic platform (head, eyes, jaw, arms, hands-lite).
  \item Series-elastic or virtual-muscle control model to emulate antagonist muscle pairs.
  \item Joint sensing for position, velocity, effort estimate, and calibration state.
  \item Quiet-mechanics priority to avoid self-noise contaminating audio learning.
\end{itemize}

\subsection{3. Sensor Layer}
\begin{itemize}
  \item Vision: low/medium-resolution monocular first, binocular second.
  \item Vision: foveated remapping and contrast-dominant preprocessing.
  \item Vision: edge/temporal-change channels for active vision experiments.
  \item Audio: microphone pair with phase/time-difference localization pipeline.
  \item Audio: cochlea-like band decomposition into tonotopic representation.
  \item Audio: directional attention map for ``cocktail party'' style source selection.
  \item Proprioception/touch: joint-angle and tension-derived body-state maps.
  \item Proprioception/touch: phased introduction of tactile patches for contact-rich learning.
\end{itemize}

\subsection{4. Learning and Behavior Stack}
\begin{itemize}
  \item Level 0: reflexes (stabilization, gaze orienting, basic protective responses)
  \item Level 1: sensorimotor calibration (self-model alignment, limb calibration)
  \item Level 2: adaptive control (tracking, reaching, auditory orienting)
  \item Level 3: developmental behaviors (babbling, imitation, guided interaction)
  \item Level 4: symbolic interfaces (optional, only after robust embodied competence)
\end{itemize}

\subsection{5. Safety and Reliability}
\begin{itemize}
  \item hard limits on joint range, current, and thermal load
  \item watchdog and fault-containment per cluster
  \item graceful degradation under node or sensor failure
  \item repeatable bring-up and calibration scripts
\end{itemize}

\section{Program Plan}
\subsection{Phase A: Source-to-Spec (2--3 weeks)}
\begin{itemize}
  \item Extract requirements from \texttt{source.pdf} into testable engineering statements.
  \item Define Lucy v2 capability matrix (must/should/could).
  \item Write GA144 hardware/software architecture spec v0.1.
\end{itemize}
\textbf{Deliverables:}
\begin{itemize}
  \item \texttt{docs/requirements.md}
  \item \texttt{docs/architecture-ga144.md}
  \item \texttt{docs/test-strategy.md}
\end{itemize}

\subsection{Phase B: Core Platform Bring-Up (4--6 weeks)}
\begin{itemize}
  \item GA144 dev stack, boot flow, messaging primitives.
  \item Minimal body rig and actuator control loop.
  \item Sensor ingest prototypes (camera + dual mic + joint sensors).
\end{itemize}
\textbf{Deliverables:}
\begin{itemize}
  \item running distributed runtime on GA144
  \item closed-loop control of at least 3--4 DoF
  \item recorded sensor telemetry pipeline
\end{itemize}

\subsection{Phase C: Bio-Inspired Pipelines (6--8 weeks)}
\begin{itemize}
  \item vision preprocessing (foveation, contrast pathways)
  \item cochlea-like audio transform and source-direction map
  \item virtual-muscle abstraction with antagonistic control semantics
\end{itemize}
\textbf{Deliverables:}
\begin{itemize}
  \item demonstrable orient-to-sound behavior
  \item visual fixation and simple tracking behavior
  \item reproducible calibration routine
\end{itemize}

\subsection{Phase D: Developmental Learning (8--12 weeks)}
\begin{itemize}
  \item motor babbling and self-calibration learning
  \item guided reaching and imitation primitives
  \item sensorimotor contingency learning experiments
\end{itemize}
\textbf{Deliverables:}
\begin{itemize}
  \item benchmark suite for emergent behavior
  \item milestone demo: guided interaction session
\end{itemize}

\subsection{Phase E: Integration and Manifesto v1 (3--4 weeks)}
\begin{itemize}
  \item consolidate findings into revised Lucy Manifesto v1.0
  \item compare original assumptions vs.\ GA144-era outcomes
  \item publish architecture, experiments, and open challenges
\end{itemize}
\textbf{Deliverables:}
\begin{itemize}
  \item \texttt{docs/manifesto-v1.md}
  \item \texttt{docs/results-and-gaps.md}
\end{itemize}

\section{Success Criteria}
\begin{itemize}
  \item Lucy v2 demonstrates stable embodied control in real hardware.
  \item At least two non-trivial behaviors emerge from learning, not scripted logic.
  \item Distributed GA144 architecture sustains real-time operation within power budget.
  \item Project produces a defensible, test-backed manifesto update.
\end{itemize}

\section{Immediate Next Actions (This Week)}
\begin{itemize}
  \item Create requirements extraction document from \texttt{source.txt}.
  \item Draft GA144 node allocation and interconnect map.
  \item Define v0 hardware BOM for torso/head/arms prototype.
  \item Stand up baseline simulation harness for sensorimotor loops before hardware integration.
\end{itemize}

\end{document}
